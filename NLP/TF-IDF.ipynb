{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://blog.csdn.net/Eastmount/article/details/50323063、https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%87%89%E7%94%A8-%E5%9E%83%E5%9C%BE%E8%A8%8A%E6%81%AF%E5%81%B5%E6%B8%AC-%E8%88%87-tf-idf%E4%BB%8B%E7%B4%B9-%E5%90%AB%E7%AF%84%E4%BE%8B%E7%A8%8B%E5%BC%8F-2cddc7f7b2c5\n",
    "'''\n",
    "TF-IDF 是一種常用於資訊檢索與文字探勘的統計方法，用來評估「詞」對於「文件」的重要程度\n",
    "TF(Term Frequency)詞頻:每個詞在文章中出現的次數，越多越能代表文章\n",
    "IDF(InversDocument Frequency):每個詞在\"所有\"文章中出現的，越多代表詞越不重要\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         1      0   1    0       2    1      0     1\n",
       "2    1         0      0   0    1       0    1      1     0\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "#文庫\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "\n",
    "#將文庫中的詞語轉成詞頻矩陣\n",
    "vectorizer = CountVectorizer()\n",
    "#計算每個詞出現幾次\n",
    "count = vectorizer.fit_transform(corpus)\n",
    "#找出詞\n",
    "word = vectorizer.get_feature_names()\n",
    "#詞頻結果\n",
    "df=pd.DataFrame(count.toarray(),columns=word)\n",
    "#print(count)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and  document     first        is       one    second       the  \\\n",
      "0  0.000000  0.438777  0.541977  0.438777  0.000000  0.000000  0.358729   \n",
      "1  0.000000  0.272301  0.000000  0.272301  0.000000  0.853226  0.222624   \n",
      "2  0.552805  0.000000  0.000000  0.000000  0.552805  0.000000  0.288477   \n",
      "3  0.000000  0.438777  0.541977  0.438777  0.000000  0.000000  0.358729   \n",
      "\n",
      "      third      this  \n",
      "0  0.000000  0.438777  \n",
      "1  0.000000  0.272301  \n",
      "2  0.552805  0.000000  \n",
      "3  0.000000  0.438777  \n",
      "總共維度: 9\n"
     ]
    }
   ],
   "source": [
    "#TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "\n",
    "#將文庫中的詞語轉成詞頻矩陣\n",
    "vectorizer = CountVectorizer()\n",
    "#計算每個詞出現幾次\n",
    "count = vectorizer.fit_transform(corpus)\n",
    "#找出詞\n",
    "word = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "Transformer = TfidfTransformer()\n",
    "#詞詞頻矩陣轉成tfidf值\n",
    "tfidf = Transformer.fit_transform(count)\n",
    "#print(tfidf)\n",
    "df=pd.DataFrame(tfidf.toarray(),columns=word)\n",
    "print(df)\n",
    "print(\"總共維度:\",len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------第 0 文本的tf-idf權重-------------\n",
      "中科院 0.0\n",
      "台北 0.0\n",
      "台灣 0.0\n",
      "台灣大學 0.0\n",
      "壽豐車站 0.7071067811865476\n",
      "小明 0.0\n",
      "畢業 0.0\n",
      "碩士 0.0\n",
      "花蓮 0.7071067811865476\n",
      "--------------第 1 文本的tf-idf權重-------------\n",
      "中科院 0.0\n",
      "台北 0.7071067811865476\n",
      "台灣 0.0\n",
      "台灣大學 0.7071067811865476\n",
      "壽豐車站 0.0\n",
      "小明 0.0\n",
      "畢業 0.0\n",
      "碩士 0.0\n",
      "花蓮 0.0\n",
      "--------------第 2 文本的tf-idf權重-------------\n",
      "中科院 0.5\n",
      "台北 0.0\n",
      "台灣 0.0\n",
      "台灣大學 0.0\n",
      "壽豐車站 0.0\n",
      "小明 0.5\n",
      "畢業 0.5\n",
      "碩士 0.5\n",
      "花蓮 0.0\n",
      "--------------第 3 文本的tf-idf權重-------------\n",
      "中科院 0.0\n",
      "台北 0.0\n",
      "台灣 1.0\n",
      "台灣大學 0.0\n",
      "壽豐車站 0.0\n",
      "小明 0.0\n",
      "畢業 0.0\n",
      "碩士 0.0\n",
      "花蓮 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "#中文要先以jieba切開\n",
    "corpus=[\"我 到 花蓮 壽豐車站\",\n",
    "\"他 到 了 台北 台灣大學\",\n",
    "\"小明 碩士 畢業 去 中科院\",\n",
    "\"我 愛 台灣\"]\n",
    "#tf\n",
    "Vectorizer=CountVectorizer()\n",
    "#idf\n",
    "Transformer=TfidfTransformer()\n",
    "\n",
    "tfidf=Transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "word=vectorizer.get_feature_names()\n",
    "\n",
    "weight=tfidf.toarray()\n",
    "for i in range(len(weight)):\n",
    "    print(\"--------------第\",i,\"文本的tf-idf權重-------------\")\n",
    "    for j in range(len(word)):\n",
    "        print(word[j],weight[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
